{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andrew Ng\n",
    "from time import time\n",
    "import multiprocessing\n",
    "import lectura\n",
    "from multiprocessing import Pool\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cpu:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of cpu: \",multiprocessing.cpu_count() )\n",
    "directorios = ['enron/enron1', 'enron/enron2', 'enron/enron3', 'enron/enron4', 'enron/enron5', 'enron/enron6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Datos\n",
    "\n",
    "La base de datos de enron contiene principalmente 6 carpetas (enron1,enron2,...enron6).\n",
    "Cada carpeta enron-iesima contiene dos carpetas.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Enron1\n",
    "        </td>\n",
    "        <td>\n",
    "            Ham: 3672\n",
    "        </td>\n",
    "        <td>\n",
    "            Spam: 1500\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Enron2\n",
    "        </td>\n",
    "        <td>\n",
    "            Ham: 4361\n",
    "        </td>\n",
    "        <td>\n",
    "            Spam: 1496\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Enron3\n",
    "        </td>\n",
    "        <td>\n",
    "            Ham: 4012\n",
    "        </td>\n",
    "        <td>\n",
    "            Spam: 1500\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Enron4\n",
    "        </td>\n",
    "        <td>\n",
    "            Ham: 1500\n",
    "        </td>\n",
    "        <td>\n",
    "            Spam: 4500\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Enron5\n",
    "        </td>\n",
    "        <td>\n",
    "            Ham: 1500\n",
    "        </td>\n",
    "        <td>\n",
    "            Spam: 3675\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Enron6\n",
    "        </td>\n",
    "        <td>\n",
    "            Ham: 1500\n",
    "        </td>\n",
    "        <td>\n",
    "            Spam: 4500\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron/enron2\n",
      "enron/enron1\n",
      "enron/enron6\n",
      "enron/enron3\n",
      "enron/enron4\n",
      "enron/enron5\n",
      "4012 1500\n",
      "1500 4500\n",
      "1500 3675\n",
      "1500 4500\n",
      "3672 1500\n",
      "4361 1496\n",
      "Tiempo : 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_time = time()\n",
    "    \n",
    "    # por default toma \n",
    "    p = Pool(6) # el tamaño de la agrupación es 2, por lo que dos ejecuciones de la función work_log suceden en paralelo\n",
    "    # cuando una de las funciones de procesamiento finaliza, selecciona el siguiente argumento y así sucesivamente\n",
    "    correosTotales = p.map(lectura.extraerCorreos,directorios) # lanzamiento \n",
    " \n",
    "    # [ham, spam]\n",
    "    elapsed_time = time() - start_time\n",
    "    print(\"Tiempo : %d\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron/enron1\n",
      " ham :  3672\n",
      " spam :  1500 \n",
      "\n",
      "enron/enron2\n",
      " ham :  4361\n",
      " spam :  1496 \n",
      "\n",
      "enron/enron3\n",
      " ham :  4012\n",
      " spam :  1500 \n",
      "\n",
      "enron/enron4\n",
      " ham :  1500\n",
      " spam :  4500 \n",
      "\n",
      "enron/enron5\n",
      " ham :  1500\n",
      " spam :  3675 \n",
      "\n",
      "enron/enron6\n",
      " ham :  1500\n",
      " spam :  4500 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for direct in range(len(directorios)):\n",
    "    print(directorios[direct])\n",
    "    print(\" ham : \", len(correosTotales[direct][0]))\n",
    "    print(\" spam : \", len(correosTotales[direct][1]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga una lista de stopwords de NLTK, para hacer la limpieza de las palabras que se utilicen para este programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'over', 'down', 'while', 'few', 'at', \"haven't\", 'have', 'each', \"wouldn't\", 'out', 'wasn', 'both', 'but', 'some', 'myself', 'above', 'should', 'herself', 'most', \"weren't\", 'her', \"isn't\", \"wasn't\", \"don't\", 'how', 'into', 'again', 'ain', \"couldn't\", 'our', 't', \"shouldn't\", \"you'd\", 'will', 'any', 'here', 'ma', 'why', 'yourselves', \"doesn't\", \"hasn't\", 'nor', 'very', 'all', 'those', 'they', 'was', 'so', 'being', 'on', 'a', 'now', \"you'll\", 'had', 'he', 'below', \"it's\", 'off', \"won't\", \"hadn't\", \"should've\", 'couldn', 'not', 'between', 'were', 've', 'needn', 'in', 'yourself', 'with', 'do', 'than', 'before', 'aren', 'haven', 'which', 'that', 'his', 'be', 'doing', 'shan', \"shan't\", 'or', 'same', 'who', 'did', 'you', 'where', 'ourselves', 'more', 'weren', 'themselves', 'too', 'about', \"you're\", 'an', 'after', 'under', 'has', 'yours', 'own', 'whom', 'then', 'their', 'theirs', 'shouldn', 'against', 'am', 's', 'hers', 'these', 'mustn', \"you've\", 'other', 'what', 'to', 'your', 'this', 're', 'itself', 'them', 'ours', 'y', 'isn', 'we', \"mustn't\", 'are', 'there', 'does', 'for', 'll', 'me', 'having', 'up', 'if', 'until', 'been', 'once', 'himself', \"mightn't\", 'the', 'it', 'didn', 'him', 'by', 'such', 'through', \"didn't\", 'mightn', \"that'll\", 'd', 'my', 'just', \"needn't\", 'don', 'when', 'm', \"she's\", 'because', 'won', 'is', 'i', 'from', 'hasn', 'only', 'no', 'doesn', 'of', 'o', 'and', 'as', 'she', 'further', 'wouldn', 'during', 'its', 'hadn', 'can', \"aren't\"}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Conjunto de datos a utilizar\n",
    "El siguiente fragmento de codigo, obtiene las palabras existentes en las carpetas enron.<br>\n",
    "<h4>Para este programa solo se utilizaron 1000 correos de la carpeta enron1, distribuidos<br>\n",
    "entre 500 ham y 500 spam.</h4>\n",
    "Las palabras son almacenadas en la variable 'bw1'.\n",
    "Nota: solo se consideran las palabras raices, se eliminan conjunciones y stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo : 45\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_time = time()\n",
    "    \n",
    "    # por default toma \n",
    "    p = Pool(6) # el tamaño de la agrupación es 2, por lo que dos ejecuciones de la función work_log suceden en paralelo\n",
    "    # cuando una de las funciones de procesamiento finaliza, selecciona el siguiente argumento y así sucesivamente\n",
    "    \n",
    "    res1 = p.apply_async(lectura.bW, ([correosTotales[0],stop_words,nlp],))      # carpeta enron1\n",
    "    bw1 = res1.get()\n",
    "    \n",
    "    #res2 = p.apply_async(lectura.bW, ([correosTotales[1],stop_words,nlp],))      # carpeta enron1\n",
    "    #bw2 = res2.get()\n",
    "    \n",
    "    #res3 = p.apply_async(lectura.bW, ([correosTotales[2],stop_words,nlp],))      # carpeta enron1\n",
    "    #bw3 = res3.get()\n",
    "    \n",
    "    #res4 = p.apply_async(lectura.bW, ([correosTotales[3],stop_words,nlp],))      # carpeta enron1\n",
    "    #bw4 = res4.get() \n",
    "    \n",
    "    #res5 = p.apply_async(lectura.bW, ([correosTotales[4],stop_words,nlp],))      # carpeta enron1\n",
    "    #bw5 = res5.get()\n",
    "    \n",
    "    #res6 = p.apply_async(lectura.bW, ([correosTotales[5],stop_words,nlp],))      # carpeta enron1\n",
    "    #bw6 = res6.get() \n",
    "    \n",
    "    elapsed_time = time() - start_time\n",
    "    print(\"Tiempo : %d\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Limpieza de las palabras\n",
    "Las palbras que fueron obtenidas en el bloque anterior, contiene basura que se necesita elimninar para u mejor entrenamiento del modelo.<br>\n",
    "La funcion 'filtradoNLTK' recibe una lista que contiene cadenas(palabras), y se hace un procesado\n",
    "    para eliminar basura en la lista con ayuda de la biblioteca de NLTK y su part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de palabras eliminadas:  4628\n",
      "cantidad de palabras guardadas:  11662\n"
     ]
    }
   ],
   "source": [
    "# primera limpieza\n",
    "bow_p = lectura.filtradoNLTK(bw1)\n",
    "print(\"cantidad de palabras eliminadas: \",len(bow_p[1]))\n",
    "print(\"cantidad de palabras guardadas: \",len(bow_p[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de palabras eliminadas:  1112 . \n",
      "cantidad de palabras guardadas:  10550 . \n"
     ]
    }
   ],
   "source": [
    "# segunda limpieza\n",
    "bow_pp = lectura.filtradoNLTK(bow_p[0])\n",
    "print(\"cantidad de palabras eliminadas: \",len(bow_pp[1]),\". \")\n",
    "print(\"cantidad de palabras guardadas: \",len(bow_pp[0]),\". \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al hacer las primeras dos limpiezas queda todavia basura, asi que la volvi a aplicar por 100 veces\n",
    "    hasta que el numero de palabras basura tendio a cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9406 0\n"
     ]
    }
   ],
   "source": [
    "bow_new = bow_pp\n",
    "for i in range(100):\n",
    "    bow_new = lectura.filtradoNLTK([str(w) for w in bow_new[0]])\n",
    "print(len(bow_new[0]),len(bow_new[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Conteo de palabras en cada correo\n",
    "Este programa se realizara con una distribución multinomial, por lo tanto se contara el número de veces que una palabra-iésima aparece en un correo-késimo. <br>\n",
    "El siguiente diccionario contendra la frequencia de palabras en los correos, cada llave es un correo-iésimo denotado: correo_enron1_'+ i + k, donde i indica si es ham (i=0) o si es spam (i=1) y k indicara de que correo se trata, recordar que son 1000 correos y los primeros 500 son hamp y el resto spam.<br>\n",
    "La primera llave del diccionario son las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia = {'WORD':list(bow_new[0])} # la primera llave del diccionario seran la palabra\n",
    "for i  in range(len(correosTotales[0])): # ham-spam para la carpeta enron1\n",
    "    for k in range(500): # k-esimo correo de ham o spam\n",
    "        t = 'correo_enron1_'+str(i)+\"_\"+str(k)\n",
    "        frequencia[t] = [0 for n in range(len(frequencia['WORD']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función calcula el conteo de las palabras en los 1000 correos, solo para la carpeta enron1.<br>\n",
    "La función modifica el diccionario declaro en la parte de arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequenciaEnron(correosTotales):\n",
    "    for i  in range(len(correosTotales[0])): # ham-spam para la carpeta enron1\n",
    "        for k in range(500): # k-esimo correo de ham o spam\n",
    "            t = 'correo_enron1_'+str(i)+\"_\"+str(k)\n",
    "            correo = str(correosTotales[0][i][k])\n",
    "            doc = nlp(str(correo))\n",
    "            for token in doc:\n",
    "                #print(token.text, token.lemma_, token.pos_)\n",
    "                for w in range(len(frequencia[\"WORD\"])):\n",
    "                    if frequencia[\"WORD\"][w] == token.lemma_: # si el token del verbo hace match con el palabra[i]\n",
    "                        frequencia[t][w] += 1 # sumamos un 1 por cada vez que aparezca el verbo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequenciaEnron(correosTotales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(frequencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sec creo un dataframe para la visualización del diccionario, y para guardar ese dataframe en un archivo csv para ser utilizado posterior mente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('frequencia_palabras.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WORD</th>\n",
       "      <th>correo_enron1_0_0</th>\n",
       "      <th>correo_enron1_0_1</th>\n",
       "      <th>correo_enron1_0_2</th>\n",
       "      <th>correo_enron1_0_3</th>\n",
       "      <th>correo_enron1_0_4</th>\n",
       "      <th>correo_enron1_0_5</th>\n",
       "      <th>correo_enron1_0_6</th>\n",
       "      <th>correo_enron1_0_7</th>\n",
       "      <th>...</th>\n",
       "      <th>correo_enron1_1_490</th>\n",
       "      <th>correo_enron1_1_491</th>\n",
       "      <th>correo_enron1_1_492</th>\n",
       "      <th>correo_enron1_1_493</th>\n",
       "      <th>correo_enron1_1_494</th>\n",
       "      <th>correo_enron1_1_495</th>\n",
       "      <th>correo_enron1_1_496</th>\n",
       "      <th>correo_enron1_1_497</th>\n",
       "      <th>correo_enron1_1_498</th>\n",
       "      <th>correo_enron1_1_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>christmas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>farm</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>picture</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>resources</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>production</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        WORD  correo_enron1_0_0  correo_enron1_0_1  \\\n",
       "0           0   christmas                  1                  0   \n",
       "1           1        farm                  1                  0   \n",
       "2           2     picture                  1                  0   \n",
       "3           3   resources                  0                  4   \n",
       "4           4  production                  0                  3   \n",
       "\n",
       "   correo_enron1_0_2  correo_enron1_0_3  correo_enron1_0_4  correo_enron1_0_5  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   correo_enron1_0_6  correo_enron1_0_7  ...  correo_enron1_1_490  \\\n",
       "0                  0                  0  ...                    0   \n",
       "1                  0                  0  ...                    0   \n",
       "2                  0                  0  ...                    0   \n",
       "3                  0                  2  ...                    0   \n",
       "4                  0                  0  ...                    0   \n",
       "\n",
       "   correo_enron1_1_491  correo_enron1_1_492  correo_enron1_1_493  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    2   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   correo_enron1_1_494  correo_enron1_1_495  correo_enron1_1_496  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   correo_enron1_1_497  correo_enron1_1_498  correo_enron1_1_499  \n",
       "0                    0                    0                    0  \n",
       "1                    2                    0                    0  \n",
       "2                    0                    0                    0  \n",
       "3                    0                    0                    0  \n",
       "4                    0                    0                    0  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('frequencia_palabras.csv') # lectura del documento con pandas\n",
    "# visualizacion\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función separa los datos para prueba y entrenamiento, el argumento 'resto' indica la cantidade de correos que se desa para los datos de prueba. <br>\n",
    "La salida son dos diccionarios, uno de entranamiento y el otro para prueba del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datosEP(data, resto):\n",
    "    conjunto1 = {'WORD':data['WORD']}\n",
    "    n_instPN = 500 - resto\n",
    "    for i in range(2):\n",
    "        for j in range(n_instPN):\n",
    "            llave = 'correo_enron1_'+str(i)+\"_\"+str(j)\n",
    "            conjunto1[llave] = data[llave]\n",
    "    conjunto2 = {'WORD':data['WORD']}\n",
    "    for i in range(2):\n",
    "        for j in range(resto):\n",
    "            llave = 'correo_enron1_'+str(i)+\"_\"+str(j)\n",
    "            conjunto2[llave] = data[llave]\n",
    "    return [conjunto1,conjunto2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801 201\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = datosEP(data,100)\n",
    "print(len(X_train.keys()),len(X_test.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD</th>\n",
       "      <th>correo_enron1_0_0</th>\n",
       "      <th>correo_enron1_0_1</th>\n",
       "      <th>correo_enron1_0_2</th>\n",
       "      <th>correo_enron1_0_3</th>\n",
       "      <th>correo_enron1_0_4</th>\n",
       "      <th>correo_enron1_0_5</th>\n",
       "      <th>correo_enron1_0_6</th>\n",
       "      <th>correo_enron1_0_7</th>\n",
       "      <th>correo_enron1_0_8</th>\n",
       "      <th>...</th>\n",
       "      <th>correo_enron1_1_390</th>\n",
       "      <th>correo_enron1_1_391</th>\n",
       "      <th>correo_enron1_1_392</th>\n",
       "      <th>correo_enron1_1_393</th>\n",
       "      <th>correo_enron1_1_394</th>\n",
       "      <th>correo_enron1_1_395</th>\n",
       "      <th>correo_enron1_1_396</th>\n",
       "      <th>correo_enron1_1_397</th>\n",
       "      <th>correo_enron1_1_398</th>\n",
       "      <th>correo_enron1_1_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>christmas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>farm</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>picture</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>resources</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>production</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 801 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         WORD  correo_enron1_0_0  correo_enron1_0_1  correo_enron1_0_2  \\\n",
       "0   christmas                  1                  0                  0   \n",
       "1        farm                  1                  0                  0   \n",
       "2     picture                  1                  0                  0   \n",
       "3   resources                  0                  4                  0   \n",
       "4  production                  0                  3                  0   \n",
       "\n",
       "   correo_enron1_0_3  correo_enron1_0_4  correo_enron1_0_5  correo_enron1_0_6  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   correo_enron1_0_7  correo_enron1_0_8  ...  correo_enron1_1_390  \\\n",
       "0                  0                  0  ...                    0   \n",
       "1                  0                  0  ...                    0   \n",
       "2                  0                  0  ...                    0   \n",
       "3                  2                  0  ...                    0   \n",
       "4                  0                  0  ...                    0   \n",
       "\n",
       "   correo_enron1_1_391  correo_enron1_1_392  correo_enron1_1_393  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    1                    0   \n",
       "\n",
       "   correo_enron1_1_394  correo_enron1_1_395  correo_enron1_1_396  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   correo_enron1_1_397  correo_enron1_1_398  correo_enron1_1_399  \n",
       "0                    0                    0                    0  \n",
       "1                    0                    0                    0  \n",
       "2                    0                    0                    0  \n",
       "3                    0                    0                    0  \n",
       "4                    0                    0                    0  \n",
       "\n",
       "[5 rows x 801 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Entrenamiento\n",
    "Para poder obtener la distribución de probabilidad de una variable aleatoria X, cada variable x tiene una distribución binomial (conteos de las palabra) y la distribución de X es la conjunción de ellas.<br>\n",
    "En este caso la variable aleatoria tiene un conjunto de 13518 posibles valores que puede tomar; es decir, fueron 13518 palabras las que se obtuvieron.<br>\n",
    "\n",
    "<br>La siguiente función realiza el entranamiento del modelo utiliza la corrección de Laplace:\n",
    "### $$ Pi = \\frac{n_i + 1}{|s| + k} $$ ### \n",
    "donde |s| es la suma de los conteos para ejemplos positivos o negativos, k es el número de valores que puede tomar la vairiable aleatoria X y ni son la suma de los conteos para la palabra-iésima.<br>\n",
    "<br> La función recibe un diccionario y devuelve dos vectores: theta_Positivo y theta_Negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train):\n",
    "    k = len(X_train['WORD']) # numero de palabras\n",
    "    print('numero de palabras: ',k)\n",
    "    datos_p = int((int(len(X_train.keys()))-1)/2)\n",
    "    print(\"datos_p: \", datos_p)\n",
    "    \n",
    "    theta_p = np.ones(k)\n",
    "    theta_n = np.ones(k)\n",
    "    \n",
    "    indice_p = 0 # indice para los correos ham\n",
    "    indice_n = 1 # indice para los correos spam\n",
    "    \n",
    "    #entranamiento para theta positivo => S_p\n",
    "    S_p = 0 # total de conteos de las instancias ham\n",
    "    for i in range(datos_p):\n",
    "        llave = 'correo_enron1_'+str(indice_p)+\"_\"+str(i)\n",
    "        S_p += np.sum(X_train[llave])\n",
    "    print(\"|S_p| = \",S_p)\n",
    "    denominador_p = S_p+k # denominador correccion de Laplace para instancias ham positiva\n",
    "    for i in range(k):\n",
    "        numerador = sumaFilaI(data,i,datos_p,indice_p) + 1\n",
    "        theta_p[i] = numerador/denominador_p\n",
    "    print(theta_p.shape)\n",
    "    \n",
    "    #entranamiento para theta negativo => S_p\n",
    "    S_n = 0 # total de conteos de las instancias ham\n",
    "    for i in range(datos_p):\n",
    "        llave = 'correo_enron1_'+str(indice_n)+\"_\"+str(i)\n",
    "        S_n += np.sum(X_train[llave])\n",
    "    print(\"|S_p| = \",S_n)\n",
    "    denominador_n = S_n+k # denominador correccion de Laplace para instancias ham positiva\n",
    "    for i in range(k):\n",
    "        numerador = sumaFilaI(data,i,datos_p,indice_n) + 1\n",
    "        theta_n[i] = numerador/denominador_n\n",
    "    print(theta_p.shape,theta_n.shape)\n",
    "    return [theta_p,theta_n]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumaFilaI(data,indiceK,datos_p,indiceI):\n",
    "    suma = 0\n",
    "    for i in range(datos_p):\n",
    "        llave = 'correo_enron1_'+str(indiceI)+\"_\"+str(i)\n",
    "        suma += X_train[llave][indiceK]\n",
    "    return suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de palabras:  10038\n",
      "datos_p:  400\n",
      "|S_p| =  24770\n",
      "(10038,)\n",
      "|S_p| =  32375\n",
      "(10038,) (10038,)\n"
     ]
    }
   ],
   "source": [
    "theta_p, theta_n = fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La suma para vector debe ser 1 \n",
      " Theta_p :  0.9999999999999999\n",
      "La suma para vector debe ser 1 \n",
      " Theta_n :  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"La suma para vector debe ser 1 \\n Theta_p : \",np.sum(theta_p))\n",
    "print(\"La suma para vector debe ser 1 \\n Theta_n : \",np.sum(theta_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Entrenamiento\n",
    "Como se utilizo la distribución miltinomial, se utilizara la formula de tal distribución para la predicción de una instancia x dado theta_positivo y theta_negativo.<br> <br>\n",
    "\n",
    "### $$ p(x|\\theta_Pos) =  \\prod_{i=1}^{k} p(x_i|\\theta_Pos) = n!*\\frac{\\theta_{1}^{x_1}}{x_1!}*...*\\frac{\\theta_k^{x_k}}{x_k!}$$ <br>\n",
    "\n",
    "### $$ p(x|\\theta_Neg) =  \\prod_{i=1}^{k} p(x_i|\\theta_Neg) = n!*\\frac{\\theta_{1}^{x_1}}{x_1!}*...*\\frac{\\theta_k^{x_k}}{x_k!}$$ <br>\n",
    "\n",
    "### $$ LR = \\frac{p(x|\\theta_Pos)}{p(x|\\theta_Neg)}$$ <br>\n",
    "\n",
    "Este modelo utiliza la razón de verosimilitud (LR) para hacer la predición.<br>\n",
    "Si LR > 1 -> y=1 <br>\n",
    "Si LR < 1 -> y=0 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(x,theta_p, theta_n):\n",
    "    \"\"\"\n",
    "        P(x)\n",
    "    \"\"\"\n",
    "    n = np.sum(x)\n",
    "    res_p = 0\n",
    "    for i in range(theta_p.shape[0]):\n",
    "        numerador = theta_p[i]**x[i]\n",
    "        denominador = np.math.factorial(x[i])\n",
    "        res_p += np.math.log(numerador/denominador)\n",
    "        #print(res_p)\n",
    "    res_p = res_p+np.math.log(np.math.factorial(n))\n",
    "    \n",
    "    res_n = 1\n",
    "    for i in range(theta_n.shape[0]):\n",
    "        numerador = theta_n[i]**x[i]\n",
    "        denominador = np.math.factorial(x[i])\n",
    "        res_n += np.math.log(numerador/denominador)\n",
    "    res_n = res_n+np.math.log(np.math.factorial(n))\n",
    "    \n",
    "    #print(res_p,res_n)\n",
    "    lr = res_p/res_n\n",
    "    if lr>1:\n",
    "        p = 1\n",
    "    if lr<1:\n",
    "        p = 0\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Funcion que tranforma un diccionario a un arreglo de numpy, sin tomar en cuenta la primera llave del diccionario\n",
    "\"\"\"\n",
    "def diccionarioArreglo(X_test):\n",
    "    listaPrin = []\n",
    "    for llave in X_test.keys():\n",
    "        if llave!=\"WORD\": # escapar las palbras\n",
    "            listaPrin.append([i for i in X_test[llave]])\n",
    "    return np.array(listaPrin).T        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función separa los datos para prueba y entrenamiento, el argumento 'procentaje' indica el procentaje de los datos de prueba que se desea. <br>\n",
    "La salida son dos arreglos de numpy, uno de entranamiento y el otro para prueba del modelo y su respetivo vector de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datosEntPrue(data, porcentaje):\n",
    "    tamTotal = len(data.keys())-2 # no se cuenta la columna de palabras en el diccionario\n",
    "    tamPrueba = int((porcentaje*tamTotal)/100)\n",
    "    tamEntrenamiento = tamTotal - tamPrueba\n",
    "    print(\"tamaño del conjunto de (prueba,entrenamiento) : \", tamPrueba,\",\",tamEntrenamiento)\n",
    "    \n",
    "    y_train = np.array([0 for i in range(int(tamEntrenamiento/2))]+[1 for i in range(int(tamEntrenamiento/2))])\n",
    "    conjunto1 = {'WORD':data['WORD']}\n",
    "    for i in range(2):\n",
    "        for j in range(int(tamEntrenamiento/2)):\n",
    "            llave = 'correo_enron1_'+str(i)+\"_\"+str(j)\n",
    "            conjunto1[llave] = data[llave]\n",
    "            \n",
    "    y_test = np.array([0 for i in range(int(tamPrueba/2))]+[1 for i in range(int(tamPrueba/2))])\n",
    "    conjunto2 = {'WORD':data['WORD']}\n",
    "    for i in range(2):\n",
    "        for j in range(int(tamPrueba/2)):\n",
    "            llave = 'correo_enron1_'+str(i)+\"_\"+str(j)\n",
    "            conjunto2[llave] = data[llave]\n",
    "    return [diccionarioArreglo(conjunto1), y_train,diccionarioArreglo(conjunto2),y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño del conjunto de (prueba,entrenamiento) :  200 , 800\n",
      "Dimension de el conjunto de entrenamiento:  (10038, 800)  con su respectivo vector de etiquetas y:  (800,)\n",
      "Dimension de el conjunto de prueba:  (10038, 200)  con su respectivo vector de etiquetas y:  (200,)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test = datosEntPrue(data, 20)\n",
    "print(\"Dimension de el conjunto de entrenamiento: \",x_train.shape,\" con su respectivo vector de etiquetas y: \",y_train.shape)\n",
    "print(\"Dimension de el conjunto de prueba: \",x_test.shape,\" con su respectivo vector de etiquetas y: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de los conjuntos de entranamiento y prueba:  (10038, 800) (10038, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension de los conjuntos de entranamiento y prueba: \",x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Test del modelo\n",
    "La siguiente función realiza el test del conjunto de pruebas.<br>\n",
    "Recibe el arreglo de datos de prueba, el vector theta positivo y negativo para el LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test,theta_p, theta_n):\n",
    "    tamEjemplos = x_test.shape[1]\n",
    "    y = np.zeros(tamEjemplos)\n",
    "    print(y.shape)\n",
    "    for i in range(tamEjemplos):\n",
    "        #print(\"si\")\n",
    "        try:\n",
    "            #print(\"eel\",P(X_test[:,i],theta_p, theta_n))\n",
    "            y[i] = P(X_test[:,i],theta_p, theta_n)\n",
    "        except:\n",
    "            y[i] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_predic = test(x_test,theta_p, theta_n)\n",
    "print(y_predic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrizCnf(y_test,y_predic):\n",
    "    \"\"\"\n",
    "        hay que recordar que por la construccion del conjunto de prueba y entrenamiento,\n",
    "        la primera mitad de los ejemplos (entrenamiento, prueba) son positivos (ham) y \n",
    "        el resto son negativos (spam)\n",
    "    \"\"\"\n",
    "    totalInstancias = y_test.shape[0]\n",
    "    tPositivo = len(np.where(y_predic[0:100]==y_test[0:100])[0]) # true positive Los primeros 100 son correos ham\n",
    "    fPositivo = len(np.where(y_predic[0:100]!=y_test[0:100])[0]) # false positive Los primeros 100 son correos ham\n",
    "    #print(tPositivo,fPositivo)\n",
    "    tNegativo = len(np.where(y_predic[100:200]==y_test[100:200])[0]) # true negative Los primeros 100 son correos spam\n",
    "    fNegativo = len(np.where(y_predic[100:200]!=y_test[100:200])[0]) # false negative Los primeros 100 son correos spam\n",
    "    #print(tNegativo,fNegativo)\n",
    "    matriz = {'1':[\"Actual: positivo\",\"Actual: negativo\"]}\n",
    "    matriz[\"prediccion: positivo\"] = [tPositivo,fPositivo]\n",
    "    matriz[\"prediccion: negativo\"] = [fNegativo,tNegativo]\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizConfusion = matrizCnf(y_test,y_predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>prediccion: positivo</th>\n",
       "      <th>prediccion: negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Actual: positivo</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Actual: negativo</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1  prediccion: positivo  prediccion: negativo\n",
       "0  Actual: positivo                    98                     2\n",
       "1  Actual: negativo                     2                    98"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(matrizConfusion).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
